{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "attempted relative import beyond top-level package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f182f2f9889b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceleba_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCelebA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: attempted relative import beyond top-level package"
     ]
    }
   ],
   "source": [
    "from ..dataset.celeba_data import CelebA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import deeppy as dp\n",
    "\n",
    "import dataset.celeba\n",
    "import aegan\n",
    "from dataset.util import img_transform, img_inverse_transform\n",
    "\n",
    "\n",
    "def run():\n",
    "    experiment_name = 'celeba'\n",
    "\n",
    "    img_size = 64\n",
    "    epoch_size = 250\n",
    "    batch_size = 64\n",
    "    n_augment = int(6e5)\n",
    "    print('preprocessing dataset')\n",
    "    train_feed, test_feed = dataset.celeba.feeds(\n",
    "        img_size, split='test', batch_size=batch_size, epoch_size=epoch_size,\n",
    "        n_augment=n_augment,\n",
    "    )\n",
    "    n_hidden = 128\n",
    "    print('building model')\n",
    "    model, experiment_name = aegan.build_model(\n",
    "        experiment_name, img_size, n_hidden=n_hidden, recon_depth=9,\n",
    "        recon_vs_gan_weight=1e-6, real_vs_gen_weight=0.5,\n",
    "        discriminate_ae_recon=False, discriminate_sample_z=True,\n",
    "    )\n",
    "    print('experiment_name: %s' % experiment_name)\n",
    "    output_dir = os.path.join('out', experiment_name)\n",
    "    aegan.train(\n",
    "        model, output_dir, train_feed, test_feed, n_epochs=250,\n",
    "        lr_start=0.025,\n",
    "    )\n",
    "    model_path = os.path.join(output_dir, 'arch.pickle')\n",
    "    print('Saving model to disk')\n",
    "    print(model_path)\n",
    "    with open(model_path, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "    print('Extracting visual attribute vectors')\n",
    "    model.phase = 'test'\n",
    "    train_feed, test_feed = dataset.celeba.feeds(\n",
    "        img_size, batch_size=batch_size, epoch_size=epoch_size,\n",
    "        with_attributes=True, split='test',\n",
    "    )\n",
    "\n",
    "    n_attr_imgs = 10000\n",
    "    x = img_transform(train_feed.x[:n_attr_imgs], to_bc01=False)\n",
    "    y = train_feed.y[:n_attr_imgs]\n",
    "    z = model.encode(x)\n",
    "\n",
    "    all_attributes = list(dp.dataset.CelebA().attribute_names)\n",
    "    selected_attributes = [\n",
    "        'Bald', 'Bangs', 'Black_Hair', 'Blond_Hair', 'Bushy_Eyebrows',\n",
    "        'Eyeglasses', 'Gray_Hair', 'Heavy_Makeup', 'High_Cheekbones', 'Male',\n",
    "        'Mustache', 'Pale_Skin', 'Rosy_Cheeks', 'Smiling', 'Straight_Hair',\n",
    "        'Wavy_Hair', 'Wearing_Lipstick', 'Young',\n",
    "    ]\n",
    "    attr_idxs = [all_attributes.index(attr) for attr in selected_attributes]\n",
    "    attr_vecs = []\n",
    "    for attr_idx in attr_idxs:\n",
    "        on_mask = y[:, attr_idx] == 1.0\n",
    "        off_mask = np.logical_not(on_mask)\n",
    "        vec = (np.mean(z[on_mask, :], axis=0, dtype=float) -\n",
    "               np.mean(z[off_mask, :], axis=0, dtype=float))\n",
    "        attr_vecs.append(vec)\n",
    "\n",
    "    print('Outputting visual attribute vectors')\n",
    "    original_x = test_feed.batches().next()[0]\n",
    "    original_z = model.encode(original_x)\n",
    "    attributes_dir = os.path.join(output_dir, 'attributes')\n",
    "    if not os.path.exists(attributes_dir):\n",
    "        os.mkdir(attributes_dir)\n",
    "    for attr_idx, attr_vec in zip(attr_idxs, attr_vecs):\n",
    "        attr_name = all_attributes[attr_idx].lower()\n",
    "        attrs_z = original_z + attr_vec\n",
    "        attrs_x = model.decode(attrs_z.astype(dp.float_))\n",
    "        attrs_x = img_inverse_transform(attrs_x)\n",
    "        for i, attr_x in enumerate(attrs_x):\n",
    "            path = os.path.join(attributes_dir, '%.3d_%s.png' % (i, attr_name))\n",
    "            sp.misc.imsave(path, attr_x)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
